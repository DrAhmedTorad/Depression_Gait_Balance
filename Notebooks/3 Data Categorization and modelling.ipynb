{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predection of Mood (Fatigue and fatigue) by different Balance parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data From File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "# Path of Raw Data on the computer\n",
    "DATA_PATH = r'C:\\Users\\ahmed\\Documents\\Depression_Gait_Balance\\Data\\Data_after_Scaling\\All_Data_After_Imputation_Winsoring_Scaled.xlsx'\n",
    "# import DATA after having the LABLE (Frist Columen is Y) columnes 2 and 3 are the neuomerical data of predectors form thim Y calculated)\n",
    "df = pd.read_excel(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y Variables\n",
    "Y_Var = ['CurrentPOMSdepression', 'Depressionsumofquestionsscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demographic_variables\n",
    "Demographic_var = ['Sex', 'Age', 'Heightcm', 'WeightinKG', 'CalculatedBMI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gait_Variables\n",
    "ANTICEPATORY_POSTURE = ['AnticipatoryPosturalAdjustmentAPADurations','AnticipatoryPosturalAdjustmentFirstStepDurations','AnticipatoryPosturalAdjustmentFirstStepRangeofMotiondegrees','AnticipatoryPosturalAdjustmentForwardAPAPeakms2','AnticipatoryPosturalAdjustmentLateralAPAPeakms2']\n",
    "BACK_ROM = ['GaitJointBackRightLat.BendMax.degreesmean','GaitJointBackRightLat.BendMax.degreesstd','GaitJointBackLeftLat.BendMax.degreesmean','GaitJointBackLeftLat.BendMax.degreesstd','GaitJointBackRLLatBendRangedegreesmean','GaitJointBackRLLatBendRangedegreesstd','GaitJointBackFlexExtMax.degreesmean','GaitJointBackFlexExtMax.degreesstd','GaitJointBackFlexExtMin.degreesmean','GaitJointBackFlexExtMin.degreesstd','GaitJointBackFlexExtRangedegreesmean','GaitJointBackFlexExtRangedegreesstd','GaitJointBackRightRotMax.degreesmean','GaitJointBackRightRotMax.degreesstd','GaitJointBackLeftRotMax.degreesmean','GaitJointBackLeftRotMax.degreesstd','GaitJointBackRLRotRangedegreesmean','GaitJointBackRLRotRangedegreesstd']\n",
    "NECK_ROM = ['GaitJointNeckRightLat.BendMax.degreesmean','GaitJointNeckRightLat.BendMax.degreesstd','GaitJointNeckLeftLat.BendMax.degreesmean','GaitJointNeckLeftLat.BendMax.degreesstd','GaitJointNeckRLLat.BendRangedegreesmean','GaitJointNeckRLLat.BendRangedegreesstd','GaitJointNeckFlexExtMax.degreesmean','GaitJointNeckFlexExtMax.degreesstd','GaitJointNeckFlexExtMin.degreesmean','GaitJointNeckFlexExtMin.degreesstd','GaitJointNeckFlexExtRangedegreesmean','GaitJointNeckFlexExtRangedegreesstd','GaitJointNeckRightRotMax.degreesmean','GaitJointNeckRightRotMax.degreesstd','GaitJointNeckLeftRotMax.degreesmean','GaitJointNeckLeftRotMax.degreesstd','GaitJointNeckRLRotRangedegreesmean','GaitJointNeckRLRotRangedegreesstd']\n",
    "CADENCE = ['GaitLowerLimbCadenceLstepsminmean','GaitLowerLimbCadenceLstepsminstd','GaitLowerLimbCadenceRstepsminmean','GaitLowerLimbCadenceRstepsminstd','Avgcadence','Cadenceasymmetry']\n",
    "DOUBLE_LIMB_SUPPORT_GCT = ['GaitLowerLimbDoubleSupportLGCTmean','GaitLowerLimbDoubleSupportLGCTstd','GaitLowerLimbDoubleSupportRGCTmean','GaitLowerLimbDoubleSupportRGCTstd','AvgdoublelegsupportofGCT','AsymetriesdoublelegsupportGCT']\n",
    "MIDSWING = ['GaitLowerLimbElevationatMidswingLcmmean','GaitLowerLimbElevationatMidswingLcmstd','GaitLowerLimbElevationatMidswingRcmmean','GaitLowerLimbElevationatMidswingRcmstd','Avgmidswingelevation','Asymetrymidswingelevation']\n",
    "GAIT_CYCLE_DURATION = ['GaitLowerLimbGaitCycleDurationLsmean','GaitLowerLimbGaitCycleDurationLsstd','GaitLowerLimbGaitCycleDurationRsmean','GaitLowerLimbGaitCycleDurationRsstd','Avggaitcycleduration','Asymmetrygaitcycleduration']\n",
    "GAIT_SPEED = ['GaitLowerLimbGaitSpeedLmsmean','GaitLowerLimbGaitSpeedLmsstd','GaitLowerLimbGaitSpeedRmsmean','GaitLowerLimbGaitSpeedRmsstd','Avggaitspeed','Asymmetrygaitspeed']\n",
    "GAIT_LATERAL_VARIATION = ['GaitLowerLimbLateralStepVariabilityLcm','GaitLowerLimbLateralStepVariabilityRcm','Avgstepvariability','Asymmetrystepvariability']\n",
    "CIRCUMDUCTION_GAIT = ['GaitLowerLimbCircumductionLcmmean','GaitLowerLimbCircumductionLcmstd','GaitLowerLimbCircumductionRcmmean','GaitLowerLimbCircumductionRcmstd','Avgcircumduction','Asymmetrycircumdunction']\n",
    "FOOT_STRIKE = ['GaitLowerLimbFootStrikeAngleLdegreesmean','GaitLowerLimbFootStrikeAngleLdegreesstd','GaitLowerLimbFootStrikeAngleRdegreesmean','GaitLowerLimbFootStrikeAngleRdegreesstd','Avgfootstrikeangle','Asymmetryfootstrikeangle']\n",
    "TOE_OFF = ['GaitLowerLimbToeOffAngleLdegreesmean','GaitLowerLimbToeOffAngleLdegreesstd','GaitLowerLimbToeOffAngleRdegreesmean','GaitLowerLimbToeOffAngleRdegreesstd','AvgToeoutangle','AsymmetryToeoutangle']\n",
    "SINGLE_LIMB_SUPPORT = ['GaitLowerLimbSingleLimbSupportLGCTmean','GaitLowerLimbSingleLimbSupportLGCTstd','GaitLowerLimbSingleLimbSupportRGCTmean','GaitLowerLimbSingleLimbSupportRGCTstd','AvgSinglelegsupportofGCT','AsymmetrySinglelegsupportofGCT']\n",
    "LIMB_STANCE = ['GaitLowerLimbStanceLGCTmean','GaitLowerLimbStanceLGCTstd','GaitLowerLimbStanceRGCTmean','GaitLowerLimbStanceRGCTstd','AvgStanceofGCT','AsymmetrystanceofGCT']\n",
    "STEP_DURATION = ['GaitLowerLimbStepDurationLsmean','GaitLowerLimbStepDurationLsstd','GaitLowerLimbStepDurationRsmean','GaitLowerLimbStepDurationRsstd','Avgstepduration','Asymmetrystepduration']\n",
    "STRIDE_LENGTH = ['GaitLowerLimbStrideLengthLmmean','GaitLowerLimbStrideLengthLmstd','GaitLowerLimbStrideLengthRmmean','GaitLowerLimbStrideLengthRmstd','Avgstridelength','Asymmetrystridelength']\n",
    "LIMB_SWING = ['GaitLowerLimbSwingLGCTmean','GaitLowerLimbSwingLGCTstd','GaitLowerLimbSwingRGCTmean','GaitLowerLimbSwingRGCTstd','AvgswingofGCT','AsymmetryswingofGCT']\n",
    "TERMINAL_DOUBLE_LIMB_SUPPORT_GCT = ['GaitLowerLimbTerminalDoubleSupportLGCTmean','GaitLowerLimbTerminalDoubleSupportLGCTstd','GaitLowerLimbTerminalDoubleSupportRGCTmean','GaitLowerLimbTerminalDoubleSupportRGCTstd','AvgterminaldoublelegsupportofGCT','AsymmetryterminaldoublelegsupportofGCT']\n",
    "TOE_OUT_ANGLE = ['GaitLowerLimbToeOutAngleLdegreesmean','GaitLowerLimbToeOutAngleLdegreesstd','GaitLowerLimbToeOutAngleRdegreesmean','GaitLowerLimbToeOutAngleRdegreesstd','AvgToeoutangle_A','AsymmetryAvgToeoutangle']\n",
    "LUMBER_ROM_IN_PLANES = ['GaitLumbarCoronalRangeofMotiondegreesmean','GaitLumbarCoronalRangeofMotiondegreesstd','GaitLumbarSagittalRangeofMotiondegreesmean','GaitLumbarSagittalRangeofMotiondegreesstd','GaitLumbarTransverseRangeofMotiondegreesmean','GaitLumbarTransverseRangeofMotiondegreesstd']\n",
    "TRUNK_POM_IN_PLANES = ['GaitTrunkCoronalRangeofMotiondegreesmean','GaitTrunkCoronalRangeofMotiondegreesstd','GaitTrunkSagittalRangeofMotiondegreesmean','GaitTrunkSagittalRangeofMotiondegreesstd','GaitTrunkTransverseRangeofMotiondegreesmean','GaitTrunkTransverseRangeofMotiondegreesstd','GaitUpperLimbArmSwingVelocityLdegreessmean','GaitUpperLimbArmSwingVelocityLdegreessstd','GaitUpperLimbArmSwingVelocityRdegreessmean','GaitUpperLimbArmSwingVelocityRdegreessstd','AvgUpperArmswingvelocity','Asymmetryupperarmswingvelocity']\n",
    "UPPER_LIMBS_ROM = ['GaitUpperLimbArmRangeofMotionLdegreesmean','GaitUpperLimbArmRangeofMotionLdegreesstd','GaitUpperLimbArmRangeofMotionRdegreesmean','GaitUpperLimbArmRangeofMotionRdegreesstd','AvgupperarmROM','AsymmetryupperarmROM']\n",
    "TURNS = ['TurnsAngledegreesmean','TurnsAngledegreesstd','TurnsDurationsmean','TurnsDurationsstd','TurnsN#','TurnsTurnVelocitydegreessmean','TurnsTurnVelocitydegreessstd','TurnsStepsinTurn#mean','TurnsStepsinTurn#std']\n",
    "Gait_SUBCATIGEROIES = ANTICEPATORY_POSTURE + BACK_ROM + NECK_ROM + CADENCE + DOUBLE_LIMB_SUPPORT_GCT + MIDSWING + GAIT_CYCLE_DURATION + GAIT_SPEED + GAIT_LATERAL_VARIATION + CIRCUMDUCTION_GAIT + FOOT_STRIKE + TOE_OFF + SINGLE_LIMB_SUPPORT + LIMB_STANCE + STEP_DURATION + STRIDE_LENGTH + LIMB_SWING + TERMINAL_DOUBLE_LIMB_SUPPORT_GCT + TOE_OUT_ANGLE + LUMBER_ROM_IN_PLANES + TRUNK_POM_IN_PLANES + UPPER_LIMBS_ROM + TURNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance_Conditions\n",
    "Condition1 = [\"PosturalSwayAcc95EllipseAxis1Radiusms2\",\"PosturalSwayAcc95EllipseAxis2Radiusms2\",\"PosturalSwayAcc95EllipseRotationms2\",\n",
    "\"PosturalSwayAcc95EllipseSwayAream2s4\",\"PosturalSwayAccCentroidalFrequencyHz\",\"PosturalSwayAccCentroidalFrequencyCoronalHz\",\n",
    "\"PosturalSwayAccCentroidalFrequencySagittalHz\",\"PosturalSwayAccFrequencyDispersionAD\",\"PosturalSwayAccFrequencyDispersionCoronalAD\",\n",
    "\"PosturalSwayAccFrequencyDispersionSagittalAD\",\"PosturalSwayAccJerkm2s5\",\"PosturalSwayAccJerkCoronalm2s5\",\n",
    "\"PosturalSwayAccJerkSagittalm2s5\",\"PosturalSwayAccMeanVelocityms\",\"PosturalSwayAccMeanVelocityCoronalms\",\n",
    "\"PosturalSwayAccMeanVelocitySagittalms\",\"PosturalSwayAccPathLengthms2\",\"PosturalSwayAccPathLengthCoronalms2\",\n",
    "\"PosturalSwayAccPathLengthSagittalms2\",\"PosturalSwayAccRMSSwayms2\",\"PosturalSwayAccRMSSwayCoronalms2\",\n",
    "\"PosturalSwayAccRMSSwaySagittalms2\",\"PosturalSwayAccRangems2\",\"PosturalSwayAccRangeCoronalms2\",\"PosturalSwayAccRangeSagittalms2\",\n",
    "\"PosturalSwayAnglesSwayAreaRadiusCoronaldegrees\",\"PosturalSwayAngles95EllipseAxis2Radiusdegrees\",\n",
    "\"PosturalSwayAnglesSwayAreaRotationdegrees\", \"PosturalSwayAnglesSwayAreadegrees2\",\"PosturalSwayAnglesDurations\",\n",
    "\"PosturalSwayAnglesRMSSwaydegrees\",\"PosturalSwayAnglesRMSSwayCoronaldegrees\",\"PosturalSwayAnglesRMSSwaySagittaldegrees\"]\n",
    "Condition2 = [\"PosturalSwayAcc95EllipseAxis1Radiusms2_A\",\"PosturalSwayAcc95EllipseAxis2Radiusms2_A\",\"PosturalSwayAcc95EllipseRotationms2_A\",\n",
    "\"PosturalSwayAcc95EllipseSwayAream2s4_A\",\"PosturalSwayAccCentroidalFrequencyHz_A\",\"PosturalSwayAccCentroidalFrequencyCoronalHz_A\",\n",
    "\"PosturalSwayAccCentroidalFrequencySagittalHz_A\",\"PosturalSwayAccFrequencyDispersionAD_A\",\"PosturalSwayAccFrequencyDispersionCoronalAD_A\",\n",
    "\"PosturalSwayAccFrequencyDispersionSagittalAD_A\",\"PosturalSwayAccJerkm2s5_A\", \"PosturalSwayAccJerkCoronalm2s5_A\",\n",
    "\"PosturalSwayAccJerkSagittalm2s5_A\",\"PosturalSwayAccMeanVelocityms_A\",\"PosturalSwayAccMeanVelocityCoronalms_A\",\n",
    "\"PosturalSwayAccMeanVelocitySagittalms_A\",\"PosturalSwayAccPathLengthms2_A\",\"PosturalSwayAccPathLengthCoronalms2_A\",\n",
    "\"PosturalSwayAccPathLengthSagittalms2_A\",\"PosturalSwayAccRMSSwayms2_A\",\"PosturalSwayAccRMSSwayCoronalms2_A\",\n",
    "\"PosturalSwayAccRMSSwaySagittalms2_A\",\"PosturalSwayAccRangems2_A\",\"PosturalSwayAccRangeCoronalms2_A\",\n",
    "\"PosturalSwayAccRangeSagittalms2_A\",\"PosturalSwayAnglesSwayAreaRadiusCoronaldegrees_A\",\"PosturalSwayAngles95EllipseAxis2Radiusdegrees_A\",\n",
    "\"PosturalSwayAnglesSwayAreaRotationdegrees_A\",\"PosturalSwayAnglesSwayAreadegrees2_A\", \"PosturalSwayAnglesDurations_A\",\n",
    "\"PosturalSwayAnglesRMSSwaydegrees_A\",\"PosturalSwayAnglesRMSSwayCoronaldegrees_A\",\"PosturalSwayAnglesRMSSwaySagittaldegrees_A\"]\n",
    "Condition3 = [\"PosturalSwayAcc95EllipseAxis1Radiusms2_B\",\"PosturalSwayAcc95EllipseAxis2Radiusms2_B\", \"PosturalSwayAcc95EllipseRotationms2_B\",\n",
    "\"PosturalSwayAcc95EllipseSwayAream2s4_B\",\"PosturalSwayAccCentroidalFrequencyHz_B\",\"PosturalSwayAccCentroidalFrequencyCoronalHz_B\",\n",
    "\"PosturalSwayAccCentroidalFrequencySagittalHz_B\",\"PosturalSwayAccFrequencyDispersionAD_B\",\"PosturalSwayAccFrequencyDispersionCoronalAD_B\",\n",
    "\"PosturalSwayAccFrequencyDispersionSagittalAD_B\",\"PosturalSwayAccJerkm2s5_B\",\"PosturalSwayAccJerkCoronalm2s5_B\",\n",
    "\"PosturalSwayAccJerkSagittalm2s5_B\",\"PosturalSwayAccMeanVelocityms_B\",\"PosturalSwayAccMeanVelocityCoronalms_B\",\n",
    "\"PosturalSwayAccMeanVelocitySagittalms_B\",\"PosturalSwayAccPathLengthms2_B\",\"PosturalSwayAccPathLengthCoronalms2_B\",\n",
    "\"PosturalSwayAccPathLengthSagittalms2_B\",\"PosturalSwayAccRMSSwayms2_B\",\"PosturalSwayAccRMSSwayCoronalms2_B\",\n",
    "\"PosturalSwayAccRMSSwaySagittalms2_B\",\"PosturalSwayAccRangems2_B\",\"PosturalSwayAccRangeCoronalms2_B\",\n",
    "\"PosturalSwayAccRangeSagittalms2_B\",\"PosturalSwayAnglesSwayAreaRadiusCoronaldegrees_B\",\"PosturalSwayAngles95EllipseAxis2Radiusdegrees_B\",\n",
    "\"PosturalSwayAnglesSwayAreaRotationdegrees_B\",\"PosturalSwayAnglesSwayAreadegrees2_B\",\"PosturalSwayAnglesDurations_B\",\n",
    "\"PosturalSwayAnglesRMSSwaydegrees_B\",\"PosturalSwayAnglesRMSSwayCoronaldegrees_B\",\"PosturalSwayAnglesRMSSwaySagittaldegrees_B\"]\n",
    "Condition4 = [\"PosturalSwayAcc95EllipseAxis1Radiusms2_C\",\"PosturalSwayAcc95EllipseAxis2Radiusms2_C\",\n",
    "\"PosturalSwayAcc95EllipseRotationms2_C\",\"PosturalSwayAcc95EllipseSwayAream2s4_C\",\"PosturalSwayAccCentroidalFrequencyHz_C\",\n",
    "\"PosturalSwayAccCentroidalFrequencyCoronalHz_C\",\"PosturalSwayAccCentroidalFrequencySagittalHz_C\",\"PosturalSwayAccFrequencyDispersionAD_C\",\n",
    "\"PosturalSwayAccFrequencyDispersionCoronalAD_C\",\"PosturalSwayAccFrequencyDispersionSagittalAD_C\",\"PosturalSwayAccJerkm2s5_C\",\n",
    "\"PosturalSwayAccJerkCoronalm2s5_C\",\"PosturalSwayAccJerkSagittalm2s5_C\",\"PosturalSwayAccMeanVelocityms_C\",\n",
    "\"PosturalSwayAccMeanVelocityCoronalms_C\",\"PosturalSwayAccMeanVelocitySagittalms_C\",\n",
    "\"PosturalSwayAccPathLengthms2_C\",\"PosturalSwayAccPathLengthCoronalms2_C\",\"PosturalSwayAccPathLengthSagittalms2_C\",\n",
    "\"PosturalSwayAccRMSSwayms2_C\",\"PosturalSwayAccRMSSwayCoronalms2_C\",\"PosturalSwayAccRMSSwaySagittalms2_C\",\n",
    "\"PosturalSwayAccRangems2_C\",\"PosturalSwayAccRangeCoronalms2_C\",\"PosturalSwayAccRangeSagittalms2_C\",\n",
    "\"PosturalSwayAnglesSwayAreaRadiusCoronaldegrees_C\",\"PosturalSwayAngles95EllipseAxis2Radiusdegrees_C\",\n",
    "\"PosturalSwayAnglesSwayAreaRotationdegrees_C\",\"PosturalSwayAnglesSwayAreadegrees2_C\",\n",
    "\"PosturalSwayAnglesDurations_C\",\"PosturalSwayAnglesRMSSwaydegrees_C\",\"PosturalSwayAnglesRMSSwayCoronaldegrees_C\",\n",
    "\"PosturalSwayAnglesRMSSwaySagittaldegrees_C\"]\n",
    "Balance_Var = Condition1 + Condition2 + Condition3 + Condition4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Var = Y_Var+Demographic_var+Gait_SUBCATIGEROIES+Balance_Var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify X and Y s and making lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify X \n",
    "X_All = df.drop(Y_Var, axis=1)\n",
    "X_Gait = df.drop(Y_Var + Balance_Var, axis=1)\n",
    "X_Balance = df.drop(Y_Var + Gait_SUBCATIGEROIES, axis=1)\n",
    "X_Balance_C1 = df.drop(Y_Var + Gait_SUBCATIGEROIES + Condition2 + Condition3 + Condition4, axis=1)\n",
    "X_Balance_C2 = df.drop(Y_Var + Gait_SUBCATIGEROIES + Condition1 + Condition3 + Condition4, axis=1)\n",
    "X_Balance_C3 = df.drop(Y_Var + Gait_SUBCATIGEROIES + Condition2 + Condition1 + Condition4, axis=1)\n",
    "X_Balance_C4 = df.drop(Y_Var + Gait_SUBCATIGEROIES + Condition2 + Condition3 + Condition1, axis=1)\n",
    "X_list = [X_All,X_Gait,X_Balance,X_Balance_C1,X_Balance_C2,X_Balance_C3,X_Balance_C4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify Y\n",
    "Y_Reg_Var = ['CurrentPOMSdepression', 'Depressionsumofquestionsscore']\n",
    "Y_POMSD = df['CurrentPOMSdepression']\n",
    "Y_SumD = df['Depressionsumofquestionsscore']\n",
    "Y_list = [Y_POMSD,Y_SumD]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# import necessary libraries\n",
    "#----------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "#----------------------------------------------------\n",
    "# Import Classifiers from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "#----------------------------------------------------\n",
    "# Import Regressors from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "#----------------------------------------------------\n",
    "# Import model metrics from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import scipy.stats as st\n",
    "#----------------------------------------------------\n",
    "# Import Confusion matrix from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#----------------------------------------------------\n",
    "# Import ROC curve from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "#----------------------------------------------------\n",
    "# Import Model evaluation metrics from libraries\n",
    "#----------------------------------------------------\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Regressors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Regressor Models\n",
    "#----------------------------------------------------\n",
    "DecisionTreeRegressorModel = DecisionTreeRegressor(random_state=33)\n",
    "LinearRegressionModel = LinearRegression(fit_intercept=True, normalize=True,copy_X=True,n_jobs=-1)\n",
    "RandomForestRegressorModel = RandomForestRegressor(random_state=33)\n",
    "RidgeRegressionModel = Ridge(alpha=1.0, random_state=33)\n",
    "LassoRegressionModel = Lasso(alpha=1.0, random_state=33,normalize=False)\n",
    "SGDRegressionModel = SGDRegressor(alpha=0.1, random_state=33,penalty='l2',loss = 'huber')\n",
    "MLPRegressorModel = MLPRegressor(activation='tanh',solver='lbfgs',learning_rate='constant',early_stopping= False, \n",
    "                    alpha=0.0001 ,hidden_layer_sizes=(100, 3),random_state=33)\n",
    "SVRModel = SVR(C = 1.0 ,epsilon=0.1,kernel = 'rbf') \n",
    "GBRModel = GradientBoostingRegressor(learning_rate = 1.5 ,random_state=33)\n",
    "NeighborsRegressorModel = KNeighborsRegressor(n_neighbors = 5, weights='uniform',algorithm = 'auto')\n",
    "#----------------------------------------------------\n",
    "# Regressor Models list\n",
    "#----------------------------------------------------\n",
    "Reg_Model_list = [DecisionTreeRegressorModel, LinearRegressionModel, RandomForestRegressorModel,\n",
    "RidgeRegressionModel, LassoRegressionModel, SGDRegressionModel, MLPRegressorModel, SVRModel, GBRModel, \n",
    "NeighborsRegressorModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressor(random_state=33),\n",
       " LinearRegression(n_jobs=-1, normalize=True),\n",
       " RandomForestRegressor(random_state=33),\n",
       " Ridge(random_state=33),\n",
       " Lasso(random_state=33),\n",
       " SGDRegressor(alpha=0.1, loss='huber', random_state=33),\n",
       " MLPRegressor(activation='tanh', hidden_layer_sizes=(100, 3), random_state=33,\n",
       "              solver='lbfgs'),\n",
       " SVR(),\n",
       " GradientBoostingRegressor(learning_rate=1.5, random_state=33),\n",
       " KNeighborsRegressor()]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_list\n",
    "Y_list\n",
    "Reg_Model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Creating for loop for y_name_list\n",
    "#----------------------------------------------------\n",
    "for y_name in Y_Reg_Var:\n",
    "    y = df[y_name].values \n",
    "    for X in X_list:\n",
    "        X_columns_names = X.columns\n",
    "        if('GaitJointBackRightLat.BendMax.degreesmean'in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns):\n",
    "            X_used = \"Whole gait and Balance conditions\"\n",
    "        elif('GaitJointBackRightLat.BendMax.degreesmean'in X.columns):\n",
    "            X_used = \"Gait\"\n",
    "        elif ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns):\n",
    "            X_used = \"Whole Balance conditions\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2' in X.columns:\n",
    "            X_used = \"Condition1\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns:\n",
    "            X_used = \"Condition2\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns:\n",
    "            X_used = \"Condition3\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns:\n",
    "            X_used = \"Condition4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Creating for loop for y_name_list\n",
    "#----------------------------------------------------\n",
    "for y_name in y_name_list:\n",
    "    y = df[y_name].values \n",
    "    for X in X_name_list:\n",
    "        X_columns_names = X.columns\n",
    "        if ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns):\n",
    "            X_used = \"Whole conditions\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2' in X.columns:\n",
    "            X_used = \"Condition1\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns:\n",
    "            X_used = \"Condition2\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns:\n",
    "            X_used = \"Condition3\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns:\n",
    "            X_used = \"Condition4\"\n",
    "        for Model_name in Model_list:\n",
    "            # Test and Train separation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=33, shuffle =False)\n",
    "            # Feature selection application\n",
    "            Model_name.fit(X, y)\n",
    "            # Get importance weights\n",
    "            from sklearn.inspection import permutation_importance\n",
    "            Model_name.score(X_test, y_test)       \n",
    "            # IF statement\n",
    "            if Model_name in [LogisticRegressionModel] :\n",
    "                importance = Model_name.coef_[0]\n",
    "                feature_Selection_method = \"the same as the regressor\"\n",
    "            elif Model_name in [GradientBoostingClassifierModel, RandomForestClassifierModel]:\n",
    "                importance = Model_name.feature_importances_\n",
    "                feature_Selection_method = \"the same as the classifier\"\n",
    "            else:\n",
    "                importance = permutation_importance (Model_name, X_test, y_test, n_repeats=5, random_state=33)\n",
    "                importance = importance.importances_mean\n",
    "                feature_Selection_method = \"permutation\"\n",
    "            # Get features names with their weights\n",
    "            feats = {} \n",
    "            for feature, importance in zip(X_columns_names, importance):\n",
    "                feats[feature] = importance  \n",
    "            importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'importance'})\n",
    "            # Sort features with top 12 important feature at the top\n",
    "            importanc_df = importances.sort_values(by ='importance' ,ascending=False).head(10)\n",
    "            # Create feature names list\n",
    "            important_features_list = importanc_df.index.tolist()\n",
    "            important_feature_importances = importanc_df.importance.tolist()\n",
    "            # Create important features dataframe\n",
    "            important_features_df = pd.DataFrame()\n",
    "            # Insert values in dataframe\n",
    "            for K in important_features_list:\n",
    "                important_features_df = important_features_df.append(df[K])\n",
    "            important_features_df = important_features_df.transpose()\n",
    "            XIF = important_features_df\n",
    "            #XIF = important_features_df.values\n",
    "            # Make X list\n",
    "            X_list = [X, XIF]\n",
    "            for Xroll in X_list:\n",
    "                X_shape = Xroll.shape\n",
    "                #Splitting data\n",
    "                X_train, X_test, y_train, y_test = train_test_split(Xroll, y, test_size=0.10, random_state=33, shuffle =True)\n",
    "                \n",
    "                    # Bootstraping method\n",
    "                    scores = []\n",
    "                    MSE = []\n",
    "                    for i in range(100):\n",
    "                        # Test and Train separation\n",
    "                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
    "                        # Feature selection application\n",
    "                        Model_name.fit(X_train, y_train)\n",
    "                        \n",
    "                        scores.append(Model_name.score(X_train,y_train))\n",
    "                        ypred = Model_name.predict(X_test)\n",
    "                        mse = mean_squared_error(y_test,ypred)\n",
    "\n",
    "                        MSE.append(mse**0.5)\n",
    "\n",
    "\n",
    "\n",
    "                    r2_score = scores\n",
    "                    Mean_r2 = np.average(r2_score)\n",
    "                    CI = st.t.interval(alpha=0.95, df=len(r2_score)-1, loc=np.mean(r2_score), scale=st.sem(r2_score))\n",
    "                    Min_r2 = np.min(r2_score)\n",
    "                    Q1_r2 = np.quantile(r2_score,0.25)\n",
    "                    Q2_r2 = np.quantile(r2_score,0.50)\n",
    "                    Q3_r2 = np.quantile(r2_score,0.75)\n",
    "                    Max_r2 = np.max(r2_score)\n",
    "                    MSE_mean = np.average(MSE)\n",
    "                    MSE_STD = np.std(MSE)*2\n",
    "\n",
    "                    '''# Cross validation using K folds\n",
    "                    CrossValidateValues1 = cross_validate(Model_name,Xroll,y,cv=cv,return_train_score = True, n_jobs=-1)\n",
    "                    explained_variance = cross_val_score(Model_name, Xroll, y, cv=cv,scoring=\"explained_variance\", n_jobs= -1)\n",
    "                    Modelcheck_mean_testscore = explained_variance.mean() \n",
    "                    Modelcheck_CI_testscore = st.t.interval(alpha=0.95, df=len(explained_variance)-1, loc=np.mean(explained_variance), scale=st.sem(explained_variance))\n",
    "                    Modelcheck_min_testscore = explained_variance.min() \n",
    "                    Modelcheck_max_testscore = explained_variance.max() \n",
    "                    test_score_Q1 = np.quantile(explained_variance, .25)\n",
    "                    test_score_Q2 = np.quantile(explained_variance, .50)\n",
    "                    test_score_Q3 = np.quantile(explained_variance, .75)\n",
    "                    Modelcheck_fitscore = CrossValidateValues1['fit_time']\n",
    "                    r2 = cross_val_score(Model_name, Xroll, y, cv=cv,scoring=\"r2\", n_jobs= -1).mean()\n",
    "                    Adj_r2 = 1 - (1-r2*(len(y)-1)/(len(y)-Xroll.shape[1]-1))\n",
    "                    mae = cross_val_score(Model_name, Xroll, y, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs= -1).mean()\n",
    "                    msqe = cross_val_score(Model_name, Xroll, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs= -1).mean()'''\n",
    "                    '''# Cross validation without using K folds\n",
    "                    CrossValidateValues1 = cross_validate(Model_name,Xroll,y,return_train_score = True, n_jobs=-1)\n",
    "                    explained_variance = cross_val_score(Model_name, Xroll, y, scoring=\"explained_variance\", n_jobs= -1)\n",
    "                    Modelcheck_mean_testscore = explained_variance.mean() \n",
    "                    Modelcheck_CI_testscore = st.t.interval(alpha=0.95, df=len(explained_variance)-1, loc=np.mean(explained_variance), scale=st.sem(explained_variance))\n",
    "                    Modelcheck_min_testscore = explained_variance.min() \n",
    "                    Modelcheck_max_testscore = explained_variance.max() \n",
    "                    test_score_Q1 = np.quantile(explained_variance, .25)\n",
    "                    test_score_Q2 = np.quantile(explained_variance, .50)\n",
    "                    test_score_Q3 = np.quantile(explained_variance, .75)\n",
    "                    Modelcheck_fitscore = CrossValidateValues1['fit_time']\n",
    "                    r2 = cross_val_score(Model_name, Xroll, y, scoring=\"r2\", n_jobs= -1).mean()\n",
    "                    Adj_r2 = 1 - (1-r2*(len(y)-1)/(len(y)-Xroll.shape[1]-1))\n",
    "                    mae = cross_val_score(Model_name, Xroll, y, scoring=\"neg_mean_absolute_error\", n_jobs= -1).mean()\n",
    "                    msqe = cross_val_score(Model_name, Xroll, y, scoring=\"neg_mean_squared_error\", n_jobs= -1).mean()'''\n",
    "                    '''# Cross validation using Montecarlo Method\n",
    "                    CrossValidateValuesMC = cross_validate(Model_name,Xroll,y,cv=MC,return_train_score = True, n_jobs=-1)\n",
    "                    explained_varianceMC = cross_val_score(Model_name, Xroll, y, scoring=\"explained_variance\", cv = MC, n_jobs= -1)\n",
    "                    Modelcheck_mean_testscoreMC = explained_varianceMC.mean() \n",
    "                    Modelcheck_CI_testscoreMC = st.t.interval(alpha=0.95, df=len(explained_varianceMC)-1, loc=np.mean(explained_varianceMC), scale=st.sem(explained_varianceMC))\n",
    "                    Modelcheck_min_testscoreMC = explained_varianceMC.min() \n",
    "                    Modelcheck_max_testscoreMC = explained_varianceMC.max() \n",
    "                    test_score_Q1MC = np.quantile(explained_varianceMC, .25)\n",
    "                    test_score_Q2MC = np.quantile(explained_varianceMC, .50)\n",
    "                    test_score_Q3MC = np.quantile(explained_varianceMC, .75)\n",
    "                    Modelcheck_fitscoreMC = CrossValidateValuesMC['fit_time']\n",
    "                    r2MC = cross_val_score(Model_name, Xroll, y, scoring=\"r2\", cv = MC, n_jobs= -1).mean()\n",
    "                    Adj_r2MC = 1 - (1-r2MC*(len(y)-1)/(len(y)-Xroll.shape[1]-1))\n",
    "                    maeMC = cross_val_score(Model_name, Xroll, y, scoring=\"neg_mean_absolute_error\", cv = MC, n_jobs= -1).mean()\n",
    "                    msqeMC = cross_val_score(Model_name, Xroll, y, scoring=\"neg_mean_squared_error\", cv = MC, n_jobs= -1).mean()'''\n",
    "                    # Insert results in dataframe\n",
    "                    results_df_reg = results_df_reg.append({'X_shape': X_shape,'y': y_name,'X_used': X_used,'important_features_list': important_features_list, \n",
    "                    'important_feature_importances':important_feature_importances, 'Model_used':Model_name,  'feature_Selection_method': feature_Selection_method,          \n",
    "                    'Mean_r2'  : Mean_r2,  'CI' :CI, 'Min_r2' : Min_r2,  'Q1_r2' :Q1_r2,  'Q2_r2': Q1_r2,  'Q3_r2':Q3_r2 ,  'Max_r2': Max_r2, 'MSE_mean':MSE_mean,\n",
    "                    'MSE_STD' : MSE_STD}, ignore_index=True)\n",
    "                    ''''MAEValue' : MAEValue, 'MSEValue' :MSEValue, 'MdSEValue' :MdSEValue, 'RSEValue' :RSEValue,''' \n",
    "                    ''''Modelcheck_mean': Modelcheck_mean_testscore,'Modelcheck_min': Modelcheck_min_testscore, \n",
    "                    'Modelcheck_Q1': test_score_Q1, 'Modelcheck_Q2': test_score_Q2,'Modelcheck_Q3': test_score_Q3,\n",
    "                    'Modelcheck_max': Modelcheck_max_testscore,'Modelcheck_CI_testscore' : Modelcheck_CI_testscore,\n",
    "                    'r2': r2, 'Adj_r2' : Adj_r2,'neg_mean_absolute_error': mae, 'neg_mean_squared_error':msqe'''\n",
    "                    ''''Modelcheck_meanMC': Modelcheck_mean_testscoreMC,'Modelcheck_minMC': Modelcheck_min_testscoreMC, \n",
    "                    'Modelcheck_Q1MC': test_score_Q1MC, 'Modelcheck_Q2MC': test_score_Q2MC,'Modelcheck_Q3MC': test_score_Q3MC,\n",
    "                    'Modelcheck_maxMC': Modelcheck_max_testscoreMC,'Modelcheck_CI_testscoreMC' : Modelcheck_CI_testscoreMC,\n",
    "                    'r2MC': r2MC, 'Adj_r2MC' : Adj_r2MC,'neg_mean_absolute_errorMC': maeMC, 'neg_mean_squared_errorMC':msqeMC'''\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rest of the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Classifier Models\n",
    "#----------------------------------------------------\n",
    "RandomForestClassifierModel = RandomForestClassifier(criterion = 'gini', random_state=33) #criterion can be also : entropy \n",
    "LogisticRegressionModel = LogisticRegression(penalty='l2', solver='sag',C=1.0,random_state=33)\n",
    "MLPClassifierModel = MLPClassifier(activation='tanh', solver='lbfgs',  learning_rate='constant', early_stopping= False, alpha=0.0001 ,hidden_layer_sizes=(100, 3),random_state=33)\n",
    "DecisionTreeClassifierModel = DecisionTreeClassifier(criterion='gini',random_state=33) \n",
    "SVCModel = SVC(kernel= 'rbf', probability=True, C=1.0,gamma='auto')\n",
    "KNNClassifierModel = KNeighborsClassifier(n_neighbors= 5,weights ='uniform', algorithm='auto') \n",
    "GaussianNBModel = GaussianNB()\n",
    "LDAModel = LinearDiscriminantAnalysis()\n",
    "GradientBoostingClassifierModel = GradientBoostingClassifier( learning_rate=1.0, random_state=33) \n",
    "BaggingClassifierModel = BaggingClassifier(base_estimator=SVC(),  random_state=33)\n",
    "#----------------------------------------------------\n",
    "# Regressor Models\n",
    "#----------------------------------------------------\n",
    "DecisionTreeRegressorModel = DecisionTreeRegressor(random_state=33)\n",
    "LinearRegressionModel = LinearRegression(fit_intercept=True, normalize=True,copy_X=True,n_jobs=-1)\n",
    "RandomForestRegressorModel = RandomForestRegressor(random_state=33)\n",
    "RidgeRegressionModel = Ridge(alpha=1.0, random_state=33)\n",
    "LassoRegressionModel = Lasso(alpha=1.0, random_state=33,normalize=False)\n",
    "SGDRegressionModel = SGDRegressor(alpha=0.1, random_state=33,penalty='l2',loss = 'huber')\n",
    "MLPRegressorModel = MLPRegressor(activation='tanh',solver='lbfgs',learning_rate='constant',early_stopping= False, \n",
    "                    alpha=0.0001 ,hidden_layer_sizes=(100, 3),random_state=33)\n",
    "SVRModel = SVR(C = 1.0 ,epsilon=0.1,kernel = 'rbf') \n",
    "GBRModel = GradientBoostingRegressor(learning_rate = 1.5 ,random_state=33)\n",
    "NeighborsRegressorModel = KNeighborsRegressor(n_neighbors = 5, weights='uniform',algorithm = 'auto')\n",
    "#----------------------------------------------------\n",
    "# Classifier and regressor list\n",
    "#----------------------------------------------------\n",
    "Model_list = [NeighborsRegressorModel,RandomForestClassifierModel, LogisticRegressionModel, LogisticRegressionModel, MLPClassifierModel,\n",
    "DecisionTreeClassifierModel, KNNClassifierModel, GaussianNBModel, LDAModel, \n",
    "GradientBoostingClassifierModel, DecisionTreeRegressorModel, \n",
    "RandomForestRegressorModel,RidgeRegressionModel,\n",
    "SGDRegressionModel,MLPRegressorModel,SVRModel,GBRModel]\n",
    "#----------------------------------------------------\n",
    "# y variable definition\n",
    "#----------------------------------------------------\n",
    "y1 ='Cate_Med_Fatigue'\n",
    "y2 ='Cate_Med_Vigor'\n",
    "y3 ='Cate_M_Fatigue_vigor'\n",
    "y4 ='CurrentPOMSFatigue'\n",
    "y5 ='CurrentPOMSVigor'\n",
    "df=df.astype({y1:'int', y2:'int', y3:'int', y4:'int', y5:'int'}) \n",
    "y_name_list = [y4, y2, y3, y1, y5]\n",
    "'''#----------------------------------------------------\n",
    "# X variable definition\n",
    "#----------------------------------------------------\n",
    "X = df.drop(['CurrentPOMSFatigue', 'Cate_Med_Fatigue', 'CurrentPOMSVigor', \n",
    "'Cate_Med_Vigor', 'Cate_M_Fatigue_vigor'], axis=1)\n",
    "X_columns_names = df.columns.drop(['CurrentPOMSFatigue', 'Cate_Med_Fatigue', 'CurrentPOMSVigor', \n",
    "'Cate_Med_Vigor', 'Cate_M_Fatigue_vigor'])'''\n",
    "#----------------------------------------------------\n",
    "# X variable definition\n",
    "#----------------------------------------------------\n",
    "X_names = Demographic_var +Condition1+Condition2+Condition3+Condition4\n",
    "X = df.drop(y_name_list, axis=1)\n",
    "X_columns_names = X.columns\n",
    "X1 = X[Demographic_var +Condition1]\n",
    "X2 = X[Demographic_var +Condition2]\n",
    "X3 = X[Demographic_var +Condition3]\n",
    "X4 = X[Demographic_var +Condition4]\n",
    "X5 = X\n",
    "X_name_list = [X1,X2,X3,X4,X5]\n",
    "#----------------------------------------------------\n",
    "# Create a cross validation variable\n",
    "#----------------------------------------------------\n",
    "k_folds=10\n",
    "repetition=3\n",
    "cv = RepeatedStratifiedKFold(n_splits=k_folds, n_repeats= repetition, random_state= 33)\n",
    "MC = ShuffleSplit(n_splits=10000,test_size=10, train_size=.90, random_state=33)\n",
    "#----------------------------------------------------\n",
    "# Create an empty dataframe for results\n",
    "#----------------------------------------------------\n",
    "results_df_reg = pd.DataFrame(columns=['X_shape','y','X_used','important_features_list', \n",
    "'important_feature_importances', 'Model_used',  'feature_Selection_method',          \n",
    "'MAEValue', 'MSEValue', 'MdSEValue', 'RSEValue', 'r2_score',\n",
    "'Mean_r2' , 'CI' , 'Min_r2',  'Q1_r2',  'Q2_r2',  'Q3_r2',  'Max_r2',\n",
    "'MSE_mean','MSE_STD'\n",
    "'Modelcheck_mean','Modelcheck_min', \n",
    "'Modelcheck_Q1', 'Modelcheck_Q2','Modelcheck_Q3',\n",
    "'Modelcheck_max','Modelcheck_CI_testscore',\n",
    "'r2', 'Adj_r2','neg_mean_absolute_error', 'neg_mean_squared_error']) \n",
    "''''Modelcheck_meanMC','Modelcheck_minMC', \n",
    "'Modelcheck_Q1MC', 'Modelcheck_Q2MC','Modelcheck_Q3MC',\n",
    "'Modelcheck_maxMC','Modelcheck_CI_testscoreMC' ,\n",
    "'r2MC', 'Adj_r2MC','neg_mean_absolute_errorMC', 'neg_mean_squared_errorMC' '''\n",
    "results_df_class =  pd.DataFrame(columns=['X_shape','y','X_used','important_features_list', \n",
    "'important_feature_importances', 'Model_used', 'feature_Selection_method',           \n",
    "'Modelcheck_mean', 'Modelcheck_min', \n",
    "'Modelcheck_Q1', 'Modelcheck_Q2','Modelcheck_Q3',\n",
    "'Modelcheck_max', 'Modelcheck_CI_testscore' ,\n",
    "'roc_F1_score_mean_score','roc_auc_mean_score', \n",
    "'roc_percesion_mean_score','roc_sensetivity_mean_score',\n",
    "'negative_log_likelihood','neg_log_loss']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------\n",
    "# Creating for loop for y_name_list\n",
    "#----------------------------------------------------\n",
    "for y_name in y_name_list:\n",
    "    y = df[y_name].values \n",
    "    for X in X_name_list:\n",
    "        X_columns_names = X.columns\n",
    "        if ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns) and ('PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns):\n",
    "            X_used = \"Whole conditions\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2' in X.columns:\n",
    "            X_used = \"Condition1\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_A' in X.columns:\n",
    "            X_used = \"Condition2\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_B' in X.columns:\n",
    "            X_used = \"Condition3\"\n",
    "        elif 'PosturalSwayAcc95EllipseAxis1Radiusms2_C' in X.columns:\n",
    "            X_used = \"Condition4\"\n",
    "        for Model_name in Model_list:\n",
    "            # Test and Train separation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=33, shuffle =False)\n",
    "            # Feature selection application\n",
    "            Model_name.fit(X, y)\n",
    "            # Get importance weights\n",
    "            from sklearn.inspection import permutation_importance\n",
    "            Model_name.score(X_test, y_test)       \n",
    "            # IF statement\n",
    "            if Model_name in [LogisticRegressionModel] :\n",
    "                importance = Model_name.coef_[0]\n",
    "                feature_Selection_method = \"the same as the regressor\"\n",
    "            elif Model_name in [GradientBoostingClassifierModel, RandomForestClassifierModel]:\n",
    "                importance = Model_name.feature_importances_\n",
    "                feature_Selection_method = \"the same as the classifier\"\n",
    "            else:\n",
    "                importance = permutation_importance (Model_name, X_test, y_test, n_repeats=5, random_state=33)\n",
    "                importance = importance.importances_mean\n",
    "                feature_Selection_method = \"permutation\"\n",
    "            # Get features names with their weights\n",
    "            feats = {} \n",
    "            for feature, importance in zip(X_columns_names, importance):\n",
    "                feats[feature] = importance  \n",
    "            importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'importance'})\n",
    "            # Sort features with top 12 important feature at the top\n",
    "            importanc_df = importances.sort_values(by ='importance' ,ascending=False).head(10)\n",
    "            # Create feature names list\n",
    "            important_features_list = importanc_df.index.tolist()\n",
    "            important_feature_importances = importanc_df.importance.tolist()\n",
    "            # Create important features dataframe\n",
    "            important_features_df = pd.DataFrame()\n",
    "            # Insert values in dataframe\n",
    "            for K in important_features_list:\n",
    "                important_features_df = important_features_df.append(df[K])\n",
    "            important_features_df = important_features_df.transpose()\n",
    "            XIF = important_features_df\n",
    "            #XIF = important_features_df.values\n",
    "            # Make X list\n",
    "            X_list = [X, XIF]\n",
    "            for Xroll in X_list:\n",
    "                X_shape = Xroll.shape\n",
    "                #Splitting data\n",
    "                X_train, X_test, y_train, y_test = train_test_split(Xroll, y, test_size=0.10, random_state=33, shuffle =True)\n",
    "                if Model_name in [RandomForestClassifierModel, LogisticRegressionModel, MLPClassifierModel,\n",
    "                DecisionTreeClassifierModel, SVCModel, KNNClassifierModel, GaussianNBModel, LDAModel, \n",
    "                GradientBoostingClassifierModel, BaggingClassifierModel]:\n",
    "                    print(\"1\")\n",
    "                    '''CrossValidateValues1 = cross_validate(Model_name,Xroll,y,cv=cv,return_train_score = True, n_jobs=-1)\n",
    "                    Modelcheck_trainscore = CrossValidateValues1['train_score']\n",
    "                    Modelcheck_testscore = CrossValidateValues1['test_score'] \n",
    "                    Modelcheck_mean_testscore = CrossValidateValues1['test_score'].mean() \n",
    "                    Modelcheck_CI_testscore = st.t.interval(alpha=0.95, df=len(Modelcheck_testscore)-1, loc=np.mean(Modelcheck_testscore), scale=st.sem(Modelcheck_testscore))\n",
    "                    Modelcheck_min_testscore = CrossValidateValues1['test_score'].min() \n",
    "                    Modelcheck_max_testscore = CrossValidateValues1['test_score'].max() \n",
    "                    test_score_Q1 = np.quantile(Modelcheck_testscore, .25)\n",
    "                    test_score_Q2 = np.quantile(Modelcheck_testscore, .50)\n",
    "                    test_score_Q3 = np.quantile(Modelcheck_testscore, .75)\n",
    "                    Modelcheck_fitscore = CrossValidateValues1['fit_time']\n",
    "                    roc_F1_score_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"f1_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                    roc_auc_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"roc_auc_ovo\", cv = cv, n_jobs= -1).mean()\n",
    "                    roc_percesion_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"precision_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                    roc_sensetivity_mean_score = cross_val_score(Model_name, Xroll, y, scoring=\"recall_macro\", cv = cv, n_jobs= -1).mean()\n",
    "                    negative_log_likelihood1 = cross_val_score(Model_name, Xroll, y, scoring=\"neg_brier_score\", cv = cv, n_jobs= -1)\n",
    "                    neg_log_loss1 = cross_val_score(Model_name, Xroll, y, scoring=\"neg_log_loss\", cv = cv, n_jobs= -1)\n",
    "                    neg_log_loss = np.median(neg_log_loss1)\n",
    "                    negative_log_likelihood = np.median(negative_log_likelihood1)\n",
    "                    # Insert results in dataframe\n",
    "                    results_df_class = results_df_class.append({'X_shape': X_shape,'y': y_name,'X_used': X_used,'important_features_list': important_features_list, \n",
    "                    'important_feature_importances':important_feature_importances, 'Model_used':Model_name, 'feature_Selection_method': feature_Selection_method,           \n",
    "                    'Modelcheck_mean': Modelcheck_mean_testscore, 'Modelcheck_min': Modelcheck_min_testscore, \n",
    "                    'Modelcheck_Q1': test_score_Q1, 'Modelcheck_Q2': test_score_Q2,'Modelcheck_Q3': test_score_Q3,\n",
    "                    'Modelcheck_max': Modelcheck_max_testscore, 'Modelcheck_CI_testscore' : Modelcheck_CI_testscore,\n",
    "                    'roc_F1_score_mean_score': roc_F1_score_mean_score,'roc_auc_mean_score': roc_auc_mean_score, \n",
    "                    'roc_percesion_mean_score': roc_percesion_mean_score,'roc_sensetivity_mean_score': roc_sensetivity_mean_score,\n",
    "                    'negative_log_likelihood': negative_log_likelihood,'neg_log_loss': [neg_log_loss]}, ignore_index=True) '''\n",
    "                else:\n",
    "                    # Bootstraping method\n",
    "                    scores = []\n",
    "                    MSE = []\n",
    "                    for i in range(100):\n",
    "                        # Test and Train separation\n",
    "                        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)\n",
    "                        # Feature selection application\n",
    "                        Model_name.fit(X_train, y_train)\n",
    "                        \n",
    "                        scores.append(Model_name.score(X_train,y_train))\n",
    "                        ypred = Model_name.predict(X_test)\n",
    "                        mse = mean_squared_error(y_test,ypred)\n",
    "\n",
    "                        MSE.append(mse**0.5)\n",
    "\n",
    "\n",
    "\n",
    "                    r2_score = scores\n",
    "                    Mean_r2 = np.average(r2_score)\n",
    "                    CI = st.t.interval(alpha=0.95, df=len(r2_score)-1, loc=np.mean(r2_score), scale=st.sem(r2_score))\n",
    "                    Min_r2 = np.min(r2_score)\n",
    "                    Q1_r2 = np.quantile(r2_score,0.25)\n",
    "                    Q2_r2 = np.quantile(r2_score,0.50)\n",
    "                    Q3_r2 = np.quantile(r2_score,0.75)\n",
    "                    Max_r2 = np.max(r2_score)\n",
    "                    MSE_mean = np.average(MSE)\n",
    "                    MSE_STD = np.std(MSE)*2\n",
    "\n",
    "                    '''# Cross validation using K folds\n",
    "                    CrossValidateValues1 = cross_validate(Model_name,Xroll,y,cv=cv,return_train_score = True, n_jobs=-1)\n",
    "                    explained_variance = cross_val_score(Model_name, Xroll, y, cv=cv,scoring=\"explained_variance\", n_jobs= -1)\n",
    "                    Modelcheck_mean_testscore = explained_variance.mean() \n",
    "                    Modelcheck_CI_testscore = st.t.interval(alpha=0.95, df=len(explained_variance)-1, loc=np.mean(explained_variance), scale=st.sem(explained_variance))\n",
    "                    Modelcheck_min_testscore = explained_variance.min() \n",
    "                    Modelcheck_max_testscore = explained_variance.max() \n",
    "                    test_score_Q1 = np.quantile(explained_variance, .25)\n",
    "                    test_score_Q2 = np.quantile(explained_variance, .50)\n",
    "                    test_score_Q3 = np.quantile(explained_variance, .75)\n",
    "                    Modelcheck_fitscore = CrossValidateValues1['fit_time']\n",
    "                    r2 = cross_val_score(Model_name, Xroll, y, cv=cv,scoring=\"r2\", n_jobs= -1).mean()\n",
    "                    Adj_r2 = 1 - (1-r2*(len(y)-1)/(len(y)-Xroll.shape[1]-1))\n",
    "                    mae = cross_val_score(Model_name, Xroll, y, cv=cv, scoring=\"neg_mean_absolute_error\", n_jobs= -1).mean()\n",
    "                    msqe = cross_val_score(Model_name, Xroll, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs= -1).mean()'''\n",
    "                    '''# Cross validation without using K folds\n",
    "                    CrossValidateValues1 = cross_validate(Model_name,Xroll,y,return_train_score = True, n_jobs=-1)\n",
    "                    explained_variance = cross_val_score(Model_name, Xroll, y, scoring=\"explained_variance\", n_jobs= -1)\n",
    "                    Modelcheck_mean_testscore = explained_variance.mean() \n",
    "                    Modelcheck_CI_testscore = st.t.interval(alpha=0.95, df=len(explained_variance)-1, loc=np.mean(explained_variance), scale=st.sem(explained_variance))\n",
    "                    Modelcheck_min_testscore = explained_variance.min() \n",
    "                    Modelcheck_max_testscore = explained_variance.max() \n",
    "                    test_score_Q1 = np.quantile(explained_variance, .25)\n",
    "                    test_score_Q2 = np.quantile(explained_variance, .50)\n",
    "                    test_score_Q3 = np.quantile(explained_variance, .75)\n",
    "                    Modelcheck_fitscore = CrossValidateValues1['fit_time']\n",
    "                    r2 = cross_val_score(Model_name, Xroll, y, scoring=\"r2\", n_jobs= -1).mean()\n",
    "                    Adj_r2 = 1 - (1-r2*(len(y)-1)/(len(y)-Xroll.shape[1]-1))\n",
    "                    mae = cross_val_score(Model_name, Xroll, y, scoring=\"neg_mean_absolute_error\", n_jobs= -1).mean()\n",
    "                    msqe = cross_val_score(Model_name, Xroll, y, scoring=\"neg_mean_squared_error\", n_jobs= -1).mean()'''\n",
    "                    '''# Cross validation using Montecarlo Method\n",
    "                    CrossValidateValuesMC = cross_validate(Model_name,Xroll,y,cv=MC,return_train_score = True, n_jobs=-1)\n",
    "                    explained_varianceMC = cross_val_score(Model_name, Xroll, y, scoring=\"explained_variance\", cv = MC, n_jobs= -1)\n",
    "                    Modelcheck_mean_testscoreMC = explained_varianceMC.mean() \n",
    "                    Modelcheck_CI_testscoreMC = st.t.interval(alpha=0.95, df=len(explained_varianceMC)-1, loc=np.mean(explained_varianceMC), scale=st.sem(explained_varianceMC))\n",
    "                    Modelcheck_min_testscoreMC = explained_varianceMC.min() \n",
    "                    Modelcheck_max_testscoreMC = explained_varianceMC.max() \n",
    "                    test_score_Q1MC = np.quantile(explained_varianceMC, .25)\n",
    "                    test_score_Q2MC = np.quantile(explained_varianceMC, .50)\n",
    "                    test_score_Q3MC = np.quantile(explained_varianceMC, .75)\n",
    "                    Modelcheck_fitscoreMC = CrossValidateValuesMC['fit_time']\n",
    "                    r2MC = cross_val_score(Model_name, Xroll, y, scoring=\"r2\", cv = MC, n_jobs= -1).mean()\n",
    "                    Adj_r2MC = 1 - (1-r2MC*(len(y)-1)/(len(y)-Xroll.shape[1]-1))\n",
    "                    maeMC = cross_val_score(Model_name, Xroll, y, scoring=\"neg_mean_absolute_error\", cv = MC, n_jobs= -1).mean()\n",
    "                    msqeMC = cross_val_score(Model_name, Xroll, y, scoring=\"neg_mean_squared_error\", cv = MC, n_jobs= -1).mean()'''\n",
    "                    # Insert results in dataframe\n",
    "                    results_df_reg = results_df_reg.append({'X_shape': X_shape,'y': y_name,'X_used': X_used,'important_features_list': important_features_list, \n",
    "                    'important_feature_importances':important_feature_importances, 'Model_used':Model_name,  'feature_Selection_method': feature_Selection_method,          \n",
    "                    'Mean_r2'  : Mean_r2,  'CI' :CI, 'Min_r2' : Min_r2,  'Q1_r2' :Q1_r2,  'Q2_r2': Q1_r2,  'Q3_r2':Q3_r2 ,  'Max_r2': Max_r2, 'MSE_mean':MSE_mean,\n",
    "                    'MSE_STD' : MSE_STD}, ignore_index=True)\n",
    "                    ''''MAEValue' : MAEValue, 'MSEValue' :MSEValue, 'MdSEValue' :MdSEValue, 'RSEValue' :RSEValue,''' \n",
    "                    ''''Modelcheck_mean': Modelcheck_mean_testscore,'Modelcheck_min': Modelcheck_min_testscore, \n",
    "                    'Modelcheck_Q1': test_score_Q1, 'Modelcheck_Q2': test_score_Q2,'Modelcheck_Q3': test_score_Q3,\n",
    "                    'Modelcheck_max': Modelcheck_max_testscore,'Modelcheck_CI_testscore' : Modelcheck_CI_testscore,\n",
    "                    'r2': r2, 'Adj_r2' : Adj_r2,'neg_mean_absolute_error': mae, 'neg_mean_squared_error':msqe'''\n",
    "                    ''''Modelcheck_meanMC': Modelcheck_mean_testscoreMC,'Modelcheck_minMC': Modelcheck_min_testscoreMC, \n",
    "                    'Modelcheck_Q1MC': test_score_Q1MC, 'Modelcheck_Q2MC': test_score_Q2MC,'Modelcheck_Q3MC': test_score_Q3MC,\n",
    "                    'Modelcheck_maxMC': Modelcheck_max_testscoreMC,'Modelcheck_CI_testscoreMC' : Modelcheck_CI_testscoreMC,\n",
    "                    'r2MC': r2MC, 'Adj_r2MC' : Adj_r2MC,'neg_mean_absolute_errorMC': maeMC, 'neg_mean_squared_errorMC':msqeMC'''\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_class.to_excel(EXPORT_PATH)  \n",
    "results_df_reg.to_excel(EXPORT_PATH2)  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "536656feb4e5b8426698a6ed7c3ac3e4cf6780e288841fc3960502355480ee44"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
